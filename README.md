# scaling-waddle
Parallel text processing engine
                                                                                                                                                                                                             
ğŸš€ Parallel Text Processing System

A Python-based parallel document analyzer that extracts text, breaks it into chunks, and processes all chunks simultaneously using multi-core CPUs.
This system detects keyword patterns, calculates frequency, and generates visual insights for large documents including PDFs, DOCX, PPTX, and TXT.

ğŸ” Problem Statement

Manual searching inside large documents (books, papers, research PDFs) is slow and inefficient.
This project enables users to search any keyword they choose and get results quickly with frequency count and chunk-wise distribution.

â— Why This Project?

To speed up text search & processing

Reduce manual reading time

Increase accuracy & accountability

Automate keyword-based content mining

ğŸ§  Thought Process

Clean text from file

Split into chunks (batches)

Assign chunks â†’ CPU workers

Run keyword detection in parallel

Generate output frequency results

Produce visual insights & CSV export

ğŸ›  How It Was Solved

Core Task	Approach

Text Extraction	PyMuPDF, DOCX, PPTX support

Cleaning	Regex preprocessing

Chunking	NLTK sentence tokenization

Pattern Matching	Regex rule engine

Parallel Execution	ProcessPoolExecutor

Result Export	CSV + SQLite database

Visualization	Matplotlib plots

ğŸ“¦ Features

âœ” Supports PDF / DOCX / PPTX / TXT
âœ” Multi-Core Parallel Execution
âœ” Custom Keyword Input
âœ” Predefined ML keyword rules
âœ” Frequency Graphs & Insights
âœ” output_rules.csv + rules.db generated

ğŸ§© Keywords Detected Automatically
Category	Examples
**Neural Networks	deep network, feedforward, etc.
Layers	hidden layer, residual layer, pooling
Neurons	relu neuron, tanh neuron
Operations	backpropagation, gradient descent
Architectures	CNN, RNN, Transformers, LSTM
Training Terms	epoch, optimizer, batch size
Math Terms	matrix, eigenvalues, dot product
Probability	bayes, entropy, distribution
Evaluation	accuracy, loss, F1Score
**
âš™ Architecture / Flow
**Load Document â†’ Extract Text â†’ Preprocess â†’ Chunk Text
          â†“                      â†“
   Parallel CPU Workers  â†  Regex Rule Engine
          â†“
   CSV + DB Output + Visualization Graphs**

ğŸ“‚ Output Files Generated
File	Description
output_rules.csv	Keyword counts per chunk
rules.db	SQLite storage of results
Graph Visuals	Match frequency charts


â–¶ Running the Program
1. Install Requirements
pip install PyMuPDF nltk python-docx python-pptx pandas matplotlib

2. Run Script
python rule_analyzer.py

3. Input Required
Enter file path: example.pdf  
Enter workers: 4  
Enter custom keywords: Matrix, Learning, Neural  

ğŸ”® Future Enhancements

Web UI using Streamlit/Flask

Heatmap keyword distribution

Topic summarization using NLP

Auto-classification of document topic

ğŸ“œ License

Open Source â€” free to modify & use.

â­ If you like this project, consider giving a star ğŸŒŸ
Parallel Text Processing â€” Fast. Smart. Scalable.
